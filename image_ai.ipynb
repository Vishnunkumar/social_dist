{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'p9.jpg'\n",
    "execution_path = os.getcwd()\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsTinyYOLOv3()\n",
    "detector.setModelPath(os.path.join(execution_path , \"yolo-tiny.h5\"))\n",
    "detector.loadModel()\n",
    "im = cv2.imread(os.path.join(execution_path , file))\n",
    "im = cv2.resize(im, (600,400))\n",
    "cv2.imwrite(os.path.join(execution_path, 'input.jpg'), im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"input.jpg\"), output_image_path=os.path.join(execution_path , \"new.jpg\"), minimum_percentage_probability = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(execution_path , \"input.jpg\")\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cent_coords(detections, img):\n",
    "    centres = []\n",
    "    coords = []\n",
    "    for i,j in enumerate(detections):\n",
    "        if j['name'] == 'person':\n",
    "            x1 = j['box_points'][0]\n",
    "            y1 = j['box_points'][1]\n",
    "            x2 = j['box_points'][2]\n",
    "            y2 = j['box_points'][3]\n",
    "            centre = (int((x2+x1)/2), int((y2+y1)/2))\n",
    "            centres.append(centre)\n",
    "            coords.append([x1, y1, x2, y2])\n",
    "    return coords, centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords, centres = get_cent_coords(detections, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_people(centres, coords, img):\n",
    "    yes = []\n",
    "    no = []\n",
    "\n",
    "    for i,j in enumerate(centres):\n",
    "        for k,l in enumerate(centres):\n",
    "            if k != i:\n",
    "                dist = abs(centres[k][0] - centres[i][0])\n",
    "                if dist < 60 and dist > 20:\n",
    "                    x1 = coords[i][0]\n",
    "                    x2 = coords[i][2]\n",
    "                    y1 = coords[i][1]\n",
    "                    y2 = coords[i][3]\n",
    "                    if k not in no:\n",
    "                        no.append(k)\n",
    "                else:\n",
    "                    x1 = coords[i][0]\n",
    "                    x2 = coords[i][2]\n",
    "                    y1 = coords[i][1]\n",
    "                    y2 = coords[i][3]\n",
    "                    if k not in yes:\n",
    "                        yes.append(k)\n",
    "    return yes, no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes, no = find_people(centres, coords, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes = list(set(yes))\n",
    "no = list(set(no))\n",
    "for n in no:\n",
    "    if n in yes:\n",
    "        yes.remove(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_people(yes, no, coords, img):    \n",
    "    for y in yes:\n",
    "        x1 = coords[y][0]\n",
    "        y1 = coords[y][1]\n",
    "        x2 = coords[y][2]\n",
    "        y2 = coords[y][3]\n",
    "    \n",
    "        cv2.rectangle(img, (x1, y1) ,(x2, y2), (0, 255, 0), 2)\n",
    "        cv2.rectangle(img, (x1, y2 - 25), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(img, \"Follow\", (x1 + 6, y2 - 6), font, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    for y in no:\n",
    "        x1 = coords[y][0]\n",
    "        y1 = coords[y][1]\n",
    "        x2 = coords[y][2]\n",
    "        y2 = coords[y][3]\n",
    "    \n",
    "        cv2.rectangle(img, (x1, y1) ,(x2, y2), (255, 0, 0), 2)\n",
    "        cv2.rectangle(img, (x1, y2 - 25), (x2, y2), (255, 0, 0), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(img, \"No_Follow\", (x1 + 6, y2 - 6), font, 0.5, (255, 255, 255), 1)\n",
    "    cv2.imwrite(os.path.join('results',('-').join([file.split('.')[0], 'results.jpg'])), img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_img = mark_people(yes, no, coords, img)\n",
    "pil = Image.fromarray(final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIDEO DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 400\n",
    "def video_detection(model, input_file, output_file, fps=30):\n",
    "    \"\"\"\n",
    "    Returns detections from video and save them in separate files\n",
    "    \"\"\"\n",
    "    # Read in the video\n",
    "    video = cv2.VideoCapture(input_file)\n",
    "\n",
    "    # Video frame dimensions\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    frame_width = int(frame_width/2)\n",
    "    frame_height = int(frame_height/2)\n",
    "    \n",
    "    # Scale down frames when passing into model for faster speeds\n",
    "    scaled_size = 800\n",
    "    scale_down_factor = min(frame_height, frame_width) / scaled_size\n",
    "\n",
    "    # The VideoWriter with which we'll write our video with the boxes and labels\n",
    "    # Parameters: filename, fourcc, fps, frame_size\n",
    "    out = cv2.VideoWriter(output_file, cv2.VideoWriter_fourcc(*'DIVX'), fps, (frame_width, frame_height))\n",
    "\n",
    "    # Loop through every frame of the video\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        # Stop the loop when we're done with the video\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        resized_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)    \n",
    "        cv2.imwrite(os.path.join('video/','input.jpg'), resized_frame)\n",
    "        detections = model.detectObjectsFromImage(input_image=os.path.join('video/','input.jpg'), output_image_path=os.path.join('video/' , \"new.jpg\"), minimum_percentage_probability = 20)\n",
    "        img_path = os.path.join('video/' , \"input.jpg\")\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        coords, centres = get_cent_coords(detections, img)\n",
    "        yes, no = find_people(centres, coords, img)\n",
    "\n",
    "        yes = list(set(yes))\n",
    "        no = list(set(no))\n",
    "        for n in no:\n",
    "            if n in yes:\n",
    "                yes.remove(n)\n",
    "                \n",
    "        final_img = mark_people(yes, no, coords, img)\n",
    "        cv2.imwrite(os.path.join('video/','new2.jpg'), final_img)\n",
    "        # Write this frame to our video file\n",
    "        out.write(final_img)\n",
    "\n",
    "        # If the 'q' key is pressed, break from the loop\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When finished, release the video capture and writer objects\n",
    "    video.release()\n",
    "    out.release()\n",
    "\n",
    "    # Close all the frames\n",
    "    cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_detection(detector, 'video.mp4', 'output/video2.avi', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIVE VIDEO DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    \n",
    "    ret, frame = video.read()\n",
    "    # Stop the loop when we're done with the video   \n",
    "    cv2.imwrite(os.path.join('video/','input.jpg'), frame)\n",
    "    detections = detector.detectObjectsFromImage(input_image=os.path.join('video/','input.jpg'), output_image_path=os.path.join('video/' , \"new.jpg\"), minimum_percentage_probability = 20)\n",
    "    print(detections)\n",
    "    img_path = os.path.join('video/' , \"new.jpg\")\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    coords, centres = get_cent_coords(detections, img)\n",
    "    yes, no = find_people(centres, coords, img)\n",
    "\n",
    "    yes = list(set(yes))\n",
    "    no = list(set(no))\n",
    "    for n in no:\n",
    "        if n in yes:\n",
    "            yes.remove(n)\n",
    "\n",
    "    final_img = mark_people(yes, no, coords, img)\n",
    "    #cv2.imwrite('')\n",
    "# Display the resulting image\n",
    "    cv2.imshow('Video', final_img)\n",
    "\n",
    "# Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# Release handle to the webcam\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
